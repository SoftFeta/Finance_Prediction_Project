{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c940fd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-18 13:43:24.426152: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-11-18 13:43:24.426191: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import horovod.tensorflow.keras as hvd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c87cb2",
   "metadata": {},
   "source": [
    "## CS5488 Project - Price Prediction on Cryptocurrencies\n",
    "### Project Group 5\n",
    "<!--\n",
    "Poon Bing-chun\n",
    "Jia Shuyue\n",
    "Li Ka-faat\n",
    "Tso Yiu-chuen\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e465a0",
   "metadata": {},
   "source": [
    "#### Objective\n",
    "In this project, we attempt to predict the exchange rates of cryptocurrencies using historical prices of other cryptocurrencies, by training a deep neural network distributedly across several machines.\n",
    "\n",
    "Distributed training is a collection of techniques for using multiple processors located on different machines for training machine learning models. It is an increasingly important deep learning technique, since it enables the training of wider neural networks which is too cumbersome to manage on one machine only.\n",
    "\n",
    "#### Plan\n",
    "The [**Horovod** library](https://github.com/horovod/horovod) ([paper](https://towardsdatascience.com/paper-summary-horovod-fast-and-easy-distributed-deep-learning-in-tensorflow-5be535c748d1)) will be used and the training machines will be grouped by an [**Apache Spark** cluster](https://horovod.readthedocs.io/en/stable/spark_include.html) (which will be covered in the last few weeks of the lecture). Horovod distributes training batches to machines for training, averages the gradients of gradient descents, and aggregates the validation metrics returned by each machine. It supports common deep learning frameworks like **Keras**, **TensorFlow** and **PyTorch**.\n",
    "\n",
    "We will compare the convergence rates with and without distributed training using TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67650d1",
   "metadata": {},
   "source": [
    "#### Data Collection\n",
    "\n",
    "We have written a Python script [**downloadData_5m.py**](https://github.com/verybighub/CS5488_Project/blob/main/downloadData_5m.py) to collect historical cryptocurrency finance data from [https://coinmarketcap.com/](https://coinmarketcap.com/). The date range is 1st January, 2019 to 22nd September, 2021 (i.e. the day we collected the data). We have parsed the data into the machine-readable `pandas` `DataFrame` format and placed it in Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdce8f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/18 13:43:40 WARN Utils: Your hostname, LAPTOP-0TFTFNMR resolves to a loopback address: 127.0.1.1; using 172.22.106.188 instead (on interface eth0)\n",
      "21/11/18 13:43:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/11/18 13:43:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/18 13:43:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"group5_project.com\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0893bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkdf = spark.read.options(header='True', delimiter=',').csv(\"historical_coin_data_5m.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa1a5e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/18 13:44:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 3:===============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------------+------------------+\n",
      "|           DateTime|          Price USD|Trading Volume Last 24h|        Market Cap|\n",
      "+-------------------+-------------------+-----------------------+------------------+\n",
      "|2019-01-01 08:04:04|       0.1146302991|       90503046.2253028|2196405505.5719624|\n",
      "|2019-01-01 09:04:00|       0.1145872532|       91258541.6394973| 2195580713.329094|\n",
      "|2019-01-01 10:04:03|       0.1144470426|       93396258.1621297|2192894168.9233046|\n",
      "|2019-01-01 11:04:02|0.11516714160000001|       96180774.6256204|2206691825.2562256|\n",
      "|2019-01-01 12:04:00|       0.1131706549|       98258636.7127816|2168437590.3445463|\n",
      "|2019-01-01 13:04:02|0.11282784850000001|       100275117.458896|2161869164.0564756|\n",
      "|2019-01-01 14:04:00|0.11273712420000001|        100027778.86779| 2160130828.079797|\n",
      "|2019-01-01 15:04:03|       0.1127905684|       100478771.924145|2161154860.0623918|\n",
      "|2019-01-01 16:04:00|       0.1129315288|       100760017.714081| 2163855781.926372|\n",
      "|2019-01-01 17:04:00|         0.11285104|       101103105.373915|2162380098.3607326|\n",
      "|2019-01-01 18:04:03|0.11232790050000001|       98957600.8917258| 2152356032.648145|\n",
      "|2019-01-01 19:04:04|0.11241133980000001|       94947809.8129728| 2153954843.436204|\n",
      "|2019-01-01 20:04:04|       0.1128717431|       95080171.9931986|2162776799.1327367|\n",
      "|2019-01-01 21:04:00|       0.1131752432|       91844682.0976247|2168592276.0433674|\n",
      "|2019-01-01 22:04:00|       0.1132890013|        88831330.169341|  2170772035.40597|\n",
      "|2019-01-01 23:04:02|       0.1132959892|        87524270.501385|2170905934.6494884|\n",
      "|2019-01-02 00:04:02|       0.1130750475|       87551868.8600877| 2166672388.359719|\n",
      "|2019-01-02 01:04:00|       0.1143625099|       88824927.2365163|  2191341927.61265|\n",
      "|2019-01-02 02:04:02|       0.1138078015|       87597249.6833761| 2180712956.789151|\n",
      "|2019-01-02 03:04:06|0.11493703790000001|        88669082.491014|2202350668.5507545|\n",
      "+-------------------+-------------------+-----------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Window\n",
    "sparkdf.count()\n",
    "\n",
    "currency = 'Stellar'\n",
    "#select hourly data\n",
    "w = Window().orderBy(F.lit(\"_c0\"))\n",
    "cdf = sparkdf.filter(sparkdf.Currency == currency).withColumn(\"id\", F.row_number().over(w)).filter(\"id % 12 == 1\")\n",
    "cdf = cdf.select(sparkdf[\"DateTime\"], \n",
    "                 sparkdf[\"Price USD\"], \n",
    "                 sparkdf[\"Trading Volume Last 24h\"],\n",
    "                 sparkdf[\"Market Cap\"])\n",
    "cdf.show()\n",
    "\n",
    "# price = cdf.select(\"Price USD\")\n",
    "# vol = cdf.select(\"Trading Volume Last 24h\")\n",
    "# marketcap = cdf.select('Market Cap')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce46e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose a currency\n",
    "# currency = 'Bitcoin'\n",
    "\n",
    "# # Originally the data has a 5-minute interval\n",
    "# # We can use Python to get hourly interval using this syntax: [::12] because 60 / 5 = 12\n",
    "# # Skip every 12 values\n",
    "# price = df[df['Currency'] == currency]['Price USD'][::12]\n",
    "# vol =  df[df['Currency'] == currency]['Trading Volume Last 24h'][::12]\n",
    "# marketcap =  df[df['Currency'] == currency]['Market Cap'][::12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca502ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(price, label='Price USD')\n",
    "# plt.plot(vol, label='Trading Volume')\n",
    "# plt.plot(marketcap, label='Market Cap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e62b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/18 13:44:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 5:===============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------------+------------------+-------------------+---------------------------+-----------------+\n",
      "|           DateTime|          Price USD|Trading Volume Last 24h|        Market Cap|          Log Price|Log Trading Volume Last 24h|   Log Market Cap|\n",
      "+-------------------+-------------------+-----------------------+------------------+-------------------+---------------------------+-----------------+\n",
      "|2019-01-01 08:04:04|       0.1146302991|       90503046.2253028|2196405505.5719624|-0.9407005744041936|         7.9566631972889015|9.341712523653495|\n",
      "|2019-01-01 09:04:00|       0.1145872532|       91258541.6394973| 2195580713.329094|-0.9408636910317881|          7.960273524233052|9.341549407147134|\n",
      "|2019-01-01 10:04:03|       0.1144470426|       93396258.1621297|2192894168.9233046|-0.9413954253493801|          7.970329476957159|9.341017672734665|\n",
      "|2019-01-01 11:04:02|0.11516714160000001|       96180774.6256204|2206691825.2562256|-0.9386714120354887|          7.983088270494887|9.343741686158557|\n",
      "|2019-01-01 12:04:00|       0.1131706549|       98258636.7127816|2168437590.3445463|-0.9462661709142547|         7.9923707342317005|9.336146927264574|\n",
      "|2019-01-01 13:04:02|0.11282784850000001|       100275117.458896|2161869164.0564756|-0.9475836932856312|          8.001193179371914|9.334829406986541|\n",
      "|2019-01-01 14:04:00|0.11273712420000001|        100027778.86779| 2160130828.079797|-0.9479330477489379|          8.000120625336544|9.334480054943759|\n",
      "|2019-01-01 15:04:03|       0.1127905684|       100478771.924145|2161154860.0623918| -0.947727214741766|           8.00207431837335|9.334685887873936|\n",
      "|2019-01-01 16:04:00|       0.1129315288|       100760017.714081| 2163855781.926372|-0.9471847925987477|          8.003288235177077|9.335228312256746|\n",
      "|2019-01-01 17:04:00|         0.11285104|       101103105.373915|2162380098.3607326|-0.9474944342452358|          8.004764495116653|9.334932035644846|\n",
      "|2019-01-01 18:04:03|0.11232790050000001|       98957600.8917258| 2152356032.648145|-0.9495123583580735|          7.995449157800177|9.332914111894562|\n",
      "|2019-01-01 19:04:04|0.11241133980000001|       94947809.8129728| 2153954843.436204|-0.9491898759185982|          7.977484951199304|9.333236594295274|\n",
      "|2019-01-01 20:04:04|       0.1128717431|       95080171.9931986|2162776799.1327367|-0.9474147680104851|          7.978089958664362|9.335011702098948|\n",
      "|2019-01-01 21:04:00|       0.1131752432|       91844682.0976247|2168592276.0433674|-0.9462485635850448|         7.9630540152687415|9.336177906597214|\n",
      "|2019-01-01 22:04:00|       0.1132890013|        88831330.169341|  2170772035.40597|-0.9458122517127997|         7.9485661653272395|9.336614218220179|\n",
      "|2019-01-01 23:04:02|       0.1132959892|        87524270.501385|2170905934.6494884|-0.9457854643567233|           7.94212849968793|9.336641005882926|\n",
      "|2019-01-02 00:04:02|       0.1130750475|       87551868.8600877| 2166672388.359719|-0.9466332211457532|          7.942265420858767| 9.33579324879847|\n",
      "|2019-01-02 01:04:00|       0.1143625099|       88824927.2365163|  2191341927.61265|-0.9417163218016439|          7.948534860396745|9.340710148299793|\n",
      "|2019-01-02 02:04:02|       0.1138078015|       87597249.6833761| 2180712956.789151| -0.943827966128386|          7.942490470710497|9.338598503961714|\n",
      "|2019-01-02 03:04:06|0.11493703790000001|        88669082.491014|2202350668.5507545|-0.9395399994788239|           7.94777221459814|9.342886470535593|\n",
      "+-------------------+-------------------+-----------------------+------------------+-------------------+---------------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time needed: 14.219001293182373 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "oldtime = time()\n",
    "from pyspark.sql.functions import col, log\n",
    "cdf = cdf.withColumn('Log Price', log(10.0, col(\"Price USD\")))\n",
    "cdf = cdf.withColumn('Log Trading Volume Last 24h', log(10.0, col(\"Trading Volume Last 24h\")))\n",
    "cdf = cdf.withColumn('Log Market Cap', log(10.0, col(\"Market Cap\")))\n",
    "cdf.show()\n",
    "print(f'Time needed: {time()-oldtime} s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cfd58ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/18 13:46:42 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "21/11/18 13:46:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "21/11/18 13:47:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "21/11/18 13:47:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 13:==============================================>           (4 + 1) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-----------------------+------------------+-------------------+---------------------------+-----------------+-------------------+------------------+--------------------+-----------------+-------------------+-------------------+-----------------+------------------+--------------------+\n",
      "|           DateTime|          Price USD|Trading Volume Last 24h|        Market Cap|          Log Price|Log Trading Volume Last 24h|   Log Market Cap|         Price_Mean|         Price_Std|    Price_Normalized|      Volume_Mean|         Volume_Std|   Volume_Normalize|      Market_Mean|        Market_Std|    Market_Normalize|\n",
      "+-------------------+-------------------+-----------------------+------------------+-------------------+---------------------------+-----------------+-------------------+------------------+--------------------+-----------------+-------------------+-------------------+-----------------+------------------+--------------------+\n",
      "|2019-01-01 08:04:04|       0.1146302991|       90503046.2253028|2196405505.5719624|-0.9407005744041936|         7.9566631972889015|9.341712523653495|-0.9220028484470751|0.3223600707160751|-0.05800261153803655|8.587220154146669|0.40435086189875397|-1.5594302282349375|9.395565742675153|0.3459356670682803| -0.1556740866822165|\n",
      "|2019-01-01 09:04:00|       0.1145872532|       91258541.6394973| 2195580713.329094|-0.9408636910317881|          7.960273524233052|9.341549407147134|-0.9220028484470751|0.3223600707160751|-0.05850861908181...|8.587220154146669|0.40435086189875397|-1.5505015297101052|9.395565742675153|0.3459356670682803| -0.1561456093434762|\n",
      "|2019-01-01 10:04:03|       0.1144470426|       93396258.1621297|2192894168.9233046|-0.9413954253493801|          7.970329476957159|9.341017672734665|-0.9220028484470751|0.3223600707160751|-0.06015812336567389|8.587220154146669|0.40435086189875397| -1.525632155926935|9.395565742675153|0.3459356670682803|-0.15768269980013666|\n",
      "|2019-01-01 11:04:02|0.11516714160000001|       96180774.6256204|2206691825.2562256|-0.9386714120354887|          7.983088270494887|9.343741686158557|-0.9220028484470751|0.3223600707160751| -0.0517079039950164|8.587220154146669|0.40435086189875397|-1.4940783873067427|9.395565742675153|0.3459356670682803|-0.14980836453145133|\n",
      "|2019-01-01 12:04:00|       0.1131706549|       98258636.7127816|2168437590.3445463|-0.9462661709142547|         7.9923707342317005|9.336146927264574|-0.9220028484470751|0.3223600707160751|-0.07526776630021881|8.587220154146669|0.40435086189875397|-1.4711219289150763|9.395565742675153|0.3459356670682803|-0.17176261677247356|\n",
      "|2019-01-01 13:04:02|0.11282784850000001|       100275117.458896|2161869164.0564756|-0.9475836932856312|          8.001193179371914|9.334829406986541|-0.9220028484470751|0.3223600707160751|-0.07935488034151375|8.587220154146669|0.40435086189875397|-1.4493031423820526|9.395565742675153|0.3459356670682803|-0.17557118698784946|\n",
      "|2019-01-01 14:04:00|0.11273712420000001|        100027778.86779| 2160130828.079797|-0.9479330477489379|          8.000120625336544|9.334480054943759|-0.9220028484470751|0.3223600707160751| -0.0804386202182631|8.587220154146669|0.40435086189875397|-1.4519556754577405|9.395565742675153|0.3459356670682803|-0.17658106274233032|\n",
      "|2019-01-01 15:04:03|       0.1127905684|       100478771.924145|2161154860.0623918| -0.947727214741766|           8.00207431837335|9.334685887873936|-0.9220028484470751|0.3223600707160751| -0.0798001012890586|8.587220154146669|0.40435086189875397|-1.4471239977716066|9.395565742675153|0.3459356670682803|-0.17598605924956562|\n",
      "|2019-01-01 16:04:00|       0.1129315288|       100760017.714081| 2163855781.926372|-0.9471847925987477|          8.003288235177077|9.335228312256746|-0.9220028484470751|0.3223600707160751|-0.07811744207567198|8.587220154146669|0.40435086189875397|-1.4441218604742416|9.395565742675153|0.3459356670682803| -0.1744180671792305|\n",
      "|2019-01-01 17:04:00|         0.11285104|       101103105.373915|2162380098.3607326|-0.9474944342452358|          8.004764495116653|9.334932035644846|-0.9220028484470751|0.3223600707160751|-0.07907798798261494|8.587220154146669|0.40435086189875397|-1.4404709224432364|9.395565742675153|0.3459356670682803|-0.17527451720767365|\n",
      "|2019-01-01 18:04:03|0.11232790050000001|       98957600.8917258| 2152356032.648145|-0.9495123583580735|          7.995449157800177|9.332914111894562|-0.9220028484470751|0.3223600707160751|-0.08533783309418572|8.587220154146669|0.40435086189875397|-1.4635086804752906|9.395565742675153|0.3459356670682803|  -0.181107751367612|\n",
      "|2019-01-01 19:04:04|0.11241133980000001|       94947809.8129728| 2153954843.436204|-0.9491898759185982|          7.977484951199304|9.333236594295274|-0.9220028484470751|0.3223600707160751|-0.08433745349146707|8.587220154146669|0.40435086189875397| -1.507935954641387|9.395565742675153|0.3459356670682803|-0.18017554798007196|\n",
      "|2019-01-01 20:04:04|       0.1128717431|       95080171.9931986|2162776799.1327367|-0.9474147680104851|          7.978089958664362|9.335011702098948|-0.9220028484470751|0.3223600707160751|-0.07883085366919397|8.587220154146669|0.40435086189875397| -1.506439710853957|9.395565742675153|0.3459356670682803|-0.17504422452124085|\n",
      "|2019-01-01 21:04:00|       0.1131752432|       91844682.0976247|2168592276.0433674|-0.9462485635850448|         7.9630540152687415|9.336177906597214|-0.9220028484470751|0.3223600707160751|-0.07521314623151507|8.587220154146669|0.40435086189875397|-1.5436250981312698|9.395565742675153|0.3459356670682803|-0.17167306447824773|\n",
      "|2019-01-01 22:04:00|       0.1132890013|        88831330.169341|  2170772035.40597|-0.9458122517127997|         7.9485661653272395|9.336614218220179|-0.9220028484470751|0.3223600707160751|-0.07385965393553706|8.587220154146669|0.40435086189875397|-1.5794549956452006|9.395565742675153|0.3459356670682803|-0.17041181371835337|\n",
      "|2019-01-01 23:04:02|       0.1132959892|        87524270.501385|2170905934.6494884|-0.9457854643567233|           7.94212849968793|9.336641005882926|-0.9220028484470751|0.3223600707160751|-0.07377655631114172|8.587220154146669|0.40435086189875397|-1.5953759846819966|9.395565742675153|0.3459356670682803|  -0.170334378329934|\n",
      "|2019-01-02 00:04:02|       0.1130750475|       87551868.8600877| 2166672388.359719|-0.9466332211457532|          7.942265420858767| 9.33579324879847|-0.9220028484470751|0.3223600707160751|-0.07640640059411004|8.587220154146669|0.40435086189875397|  -1.59503736497387|9.395565742675153|0.3459356670682803|-0.17278499896596256|\n",
      "|2019-01-02 01:04:00|       0.1143625099|       88824927.2365163|  2191341927.61265|-0.9417163218016439|          7.948534860396745|9.340710148299793|-0.9220028484470751|0.3223600707160751|-0.06115358304388688|8.587220154146669|0.40435086189875397|-1.5795324158597814|9.395565742675153|0.3459356670682803|-0.15857166403293174|\n",
      "|2019-01-02 02:04:02|       0.1138078015|       87597249.6833761| 2180712956.789151| -0.943827966128386|          7.942490470710497|9.338598503961714|-0.9220028484470751|0.3223600707160751|  -0.067704159615146|8.587220154146669|0.40435086189875397| -1.594480794250433|9.395565742675153|0.3459356670682803|-0.16467581731661815|\n",
      "|2019-01-02 03:04:06|0.11493703790000001|        88669082.491014|2202350668.5507545|-0.9395399994788239|           7.94777221459814|9.342886470535593|-0.9220028484470751|0.3223600707160751| -0.0544023674917077|8.587220154146669|0.40435086189875397|-1.5814185149644657|9.395565742675153|0.3459356670682803|-0.15228054564596943|\n",
      "+-------------------+-------------------+-----------------------+------------------+-------------------+---------------------------+-----------------+-------------------+------------------+--------------------+-----------------+-------------------+-------------------+-----------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Time needed: 54.447521448135376 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# # Data scaling - Normalization\n",
    "oldtime = time()\n",
    "from pyspark.sql.functions import mean as _mean\n",
    "from pyspark.sql.functions import stddev as _std\n",
    "# Data scaling\n",
    "def column_statistics(df, name=\"\"):\n",
    "    df_stats = df.select(\n",
    "        _mean(col(name)).alias('mean'),\n",
    "        _std(col(name)).alias('std')\n",
    "    ).collect()\n",
    "    \n",
    "    return df_stats[0]['mean'], df_stats[0]['std']\n",
    "\n",
    "data_p_mean, data_p_std = column_statistics(cdf, \"Log Price\")\n",
    "data_v_mean, data_v_std = column_statistics(cdf, \"Log Trading Volume Last 24h\")\n",
    "data_m_mean, data_m_std = column_statistics(cdf, \"Log Market Cap\")\n",
    "\n",
    "cdf = cdf.withColumn(\"Price_Mean\", f.lit(data_p_mean))\n",
    "cdf = cdf.withColumn(\"Price_Std\", f.lit(data_p_std))\n",
    "cdf = cdf.withColumn(\"Price_Normalized\", (f.col(\"Log Price\") - f.col(\"Price_Mean\")) / f.col(\"Price_Std\"))\n",
    "\n",
    "cdf = cdf.withColumn(\"Volume_Mean\", f.lit(data_v_mean))\n",
    "cdf = cdf.withColumn(\"Volume_Std\", f.lit(data_v_std))\n",
    "cdf = cdf.withColumn(\"Volume_Normalize\", (f.col(\"Log Trading Volume Last 24h\") - f.col(\"Volume_Mean\")) / f.col(\"Volume_Std\"))\n",
    "\n",
    "cdf = cdf.withColumn(\"Market_Mean\", f.lit(data_m_mean))\n",
    "cdf = cdf.withColumn(\"Market_Std\", f.lit(data_m_std))\n",
    "cdf = cdf.withColumn(\"Market_Normalize\", (f.col(\"Log Market Cap\") - f.col(\"Market_Mean\")) / f.col(\"Market_Std\"))\n",
    "cdf.show()\n",
    "print(f'Time needed: {time()-oldtime} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ab40b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/16 22:40:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "feats_scaled = cdf.select(cdf[\"Price_Normalized\"], cdf[\"Volume_Normalize\"], cdf[\"Market_Normalize\"])\n",
    "feats_scaled = feats_scaled.toPandas().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab0ba6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23880, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b9ea9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Xs:\n",
      "\n",
      "[[[-1.51537513 -2.69691701 -1.53550281]\n",
      "  [-1.51672965 -2.69585777 -1.53682049]\n",
      "  [-1.5190318  -2.69271461 -1.53906312]\n",
      "  ...\n",
      "  [-1.50103445 -2.79822043 -1.52130626]\n",
      "  [-1.50194935 -2.78721045 -1.52219748]\n",
      "  [-1.50591149 -2.78512901 -1.52606424]]\n",
      "\n",
      " [[-1.51672965 -2.69585777 -1.53682049]\n",
      "  [-1.5190318  -2.69271461 -1.53906312]\n",
      "  [-1.51737651 -2.69123981 -1.53743677]\n",
      "  ...\n",
      "  [-1.50194935 -2.78721045 -1.52219748]\n",
      "  [-1.50591149 -2.78512901 -1.52606424]\n",
      "  [-1.50383709 -2.78256111 -1.52403061]]\n",
      "\n",
      " [[-1.5190318  -2.69271461 -1.53906312]\n",
      "  [-1.51737651 -2.69123981 -1.53743677]\n",
      "  [-1.53485904 -2.68932467 -1.55452633]\n",
      "  ...\n",
      "  [-1.50591149 -2.78512901 -1.52606424]\n",
      "  [-1.50383709 -2.78256111 -1.52403061]\n",
      "  [-1.50398199 -2.80991918 -1.52416626]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.5823902   0.05574923  1.58392278]\n",
      "  [ 1.58082987  0.054354    1.58239699]\n",
      "  [ 1.57607854  0.04324676  1.57775756]\n",
      "  ...\n",
      "  [ 1.42659067  0.72916515  1.43165383]\n",
      "  [ 1.42124992  0.8473787   1.42643129]\n",
      "  [ 1.44902523  0.9146494   1.45359663]]\n",
      "\n",
      " [[ 1.58082987  0.054354    1.58239699]\n",
      "  [ 1.57607854  0.04324676  1.57775756]\n",
      "  [ 1.58295768  0.02687828  1.58448445]\n",
      "  ...\n",
      "  [ 1.42124992  0.8473787   1.42643129]\n",
      "  [ 1.44902523  0.9146494   1.45359663]\n",
      "  [ 1.45066973  0.85649845  1.45520473]]\n",
      "\n",
      " [[ 1.57607854  0.04324676  1.57775756]\n",
      "  [ 1.58295768  0.02687828  1.58448445]\n",
      "  [ 1.5764186   0.01461575  1.57809487]\n",
      "  ...\n",
      "  [ 1.44902523  0.9146494   1.45359663]\n",
      "  [ 1.45066973  0.85649845  1.45520473]\n",
      "  [ 1.44486498  0.84996225  1.44953361]]]\n",
      "-----------------------\n",
      "Ys:\n",
      "\n",
      "[[-1.50383709 -1.50398199 -1.50535667]\n",
      " [-1.50398199 -1.50535667 -1.50479777]\n",
      " [-1.50535667 -1.50479777 -1.50988284]\n",
      " ...\n",
      " [ 1.45066973  1.44486498  1.43386502]\n",
      " [ 1.44486498  1.43386502  1.44782859]\n",
      " [ 1.43386502  1.44782859  1.45077354]]\n",
      "-----------------------\n",
      "Xs:\n",
      "\n",
      "(23843, 35, 3)\n",
      "-----------------------\n",
      "Ys:\n",
      "\n",
      "(23843, 3)\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling o341.withColumn. Trace:\npy4j.Py4JException: Method withColumn([class java.util.ArrayList, class org.apache.spark.sql.Column]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1788/3926396848.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mYs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'label_vec'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0moverall_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_vec'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_vec'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Split the data into training set and testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2094\u001b[0m         \"\"\"\n\u001b[1;32m   2095\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m                 raise Py4JError(\n\u001b[0m\u001b[1;32m    331\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     format(target_id, \".\", name, value))\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling o341.withColumn. Trace:\npy4j.Py4JException: Method withColumn([class java.util.ArrayList, class org.apache.spark.sql.Column]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:326)\n\tat py4j.Gateway.invoke(Gateway.java:274)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\n"
     ]
    }
   ],
   "source": [
    "# Determine best sliding window size\n",
    "# size: 3 * 7 => last three days\n",
    "sliding_window = np.lib.stride_tricks.sliding_window_view(feats_scaled, (5 * 7 + 3, 3), axis=(0, 1))\n",
    "sliding_window = sliding_window.reshape((sliding_window.shape[0], \n",
    "                                         sliding_window.shape[2], \n",
    "                                         sliding_window.shape[3]))\n",
    "\n",
    "# Xs: Price, volume, market cap and price of the past week\n",
    "Xs = np.array([i[:-3] for i in sliding_window])\n",
    "\n",
    "# Xs: Price of the next three hours\n",
    "Ys = np.array([i[-3:,0] for i in sliding_window])\n",
    "\n",
    "print('-----------------------\\nXs:\\n')\n",
    "print(Xs)\n",
    "print('-----------------------\\nYs:\\n')\n",
    "print(Ys)\n",
    "print('-----------------------\\nXs:\\n')\n",
    "print(Xs.shape)\n",
    "print('-----------------------\\nYs:\\n')\n",
    "print(Ys.shape)\n",
    "\n",
    "Xs = np.reshape(Xs, [-1, 5 * 7 * 3])\n",
    "Xs = pd.DataFrame(Xs)\n",
    "Xs = spark.createDataFrame(Xs)\n",
    "\n",
    "Ys = pd.DataFrame(Ys)\n",
    "Ys = spark.createDataFrame(Ys)\n",
    "\n",
    "# Xs: Price, volume, market cap and price of the past week\n",
    "Xs = np.array([i[:-3] for i in sliding_window])\n",
    "Xs = np.reshape(Xs, [-1, 5 * 7 * 3])\n",
    "Xs = pd.DataFrame(Xs)\n",
    "Xs = spark.createDataFrame(Xs, ['features' * 5 * 7 * 3])\n",
    "\n",
    "# Xs: Price of the next three hours\n",
    "Ys = np.array([i[-3:,0] for i in sliding_window])\n",
    "Ys = pd.DataFrame(Ys)\n",
    "Ys = spark.createDataFrame(Ys, ['label_vec' * 3])\n",
    "\n",
    "overall_df = Xs.withColumn(['label_vec' * 3], Ys['label_vec' * 3])\n",
    "\n",
    "# Split the data into training set and testing set\n",
    "train_test_ratio = 0.8\n",
    "num_data = overall_df.count()\n",
    "train_df = overall_df.limit(int(train_test_ratio * num_data))\n",
    "test_df = overall_df.tail(int((1 - train_test_ratio) * num_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8c9842",
   "metadata": {},
   "source": [
    "# Data splitting\n",
    "We will use the holdout method. The split percentages are 90% for training, 5% for verification, and 5% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5790b96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21458, 35, 3)\n",
      "(1192, 35, 3)\n",
      "(1193, 35, 3)\n",
      "(21458, 3, 1)\n",
      "(1192, 3, 1)\n",
      "(1193, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "'''TrainLen = int(len(Xs) * 0.90)\n",
    "ValLen = int(len(Xs) * 0.95)\n",
    "TestLen = len(Xs) - TrainLen\n",
    "\n",
    "x_train = Xs[0:TrainLen,:]\n",
    "y_train = Ys[0:TrainLen]\n",
    "\n",
    "x_val = Xs[TrainLen:ValLen,:]\n",
    "y_val = Ys[TrainLen:ValLen]\n",
    "\n",
    "x_test = Xs[ValLen:,:]\n",
    "y_test = Ys[ValLen:]\n",
    "\n",
    "y_train = y_train.reshape((y_train.shape[0],y_train.shape[1],1))\n",
    "y_val = y_val.reshape((y_val.shape[0],y_val.shape[1],1))\n",
    "y_test = y_test.reshape((y_test.shape[0],y_test.shape[1],1))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30baa99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/16 22:55:45 WARN TaskSetManager: Stage 19 contains a task of very large size (22084 KiB). The maximum recommended task size is 1000 KiB.\n",
      "21/11/16 22:55:45 WARN TaskSetManager: Stage 21 contains a task of very large size (22084 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split the data into training set and testing set\n",
    "train_test_ratio = 0.8\n",
    "num_data = Xs.count()\n",
    "train_data = Xs.limit(int(train_test_ratio * num_data))\n",
    "train_label = Ys.limit(int(train_test_ratio * num_data))\n",
    "\n",
    "test_data = Xs.tail(int((1 - train_test_ratio) * num_data))\n",
    "test_label = Ys.tail(int((1 - train_test_ratio) * num_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b65576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Horovod on spark\n",
    "import horovod.spark.keras as hvd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67341ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horovod: initialize Horovod\n",
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8ce959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 22:19:46.809565: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-11-16 22:19:46.809615: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-16 22:19:46.809634: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-0TFTFNMR): /proc/driver/nvidia/version does not exist\n",
      "2021-11-16 22:19:46.809858: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/kennyli/.local/lib/python3.8/site-packages/horovod/_keras/callbacks.py:58: UserWarning: Some callbacks may not have access to the averaged metrics, see https://github.com/horovod/horovod/issues/2440\n",
      "  warnings.warn(\n",
      "2021-11-16 22:19:46.882997: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-16 22:19:46.883045: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-16 22:19:46.883268: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-16 22:19:47.031866: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "  2/671 [..............................] - ETA: 3:37 - loss: 1.3149 - mean_squared_error: 1.3149 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 22:19:50.557599: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2021-11-16 22:19:50.557644: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2021-11-16 22:19:50.663056: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2021-11-16 22:19:50.680478: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2021-11-16 22:19:50.737309: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/train/plugins/profile/2021_11_16_22_19_50\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "  3/671 [..............................] - ETA: 3:18 - loss: 1.2185 - mean_squared_error: 1.2185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 22:19:50.773645: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/train/plugins/profile/2021_11_16_22_19_50/LAPTOP-0TFTFNMR.trace.json.gz\n",
      "2021-11-16 22:19:50.800051: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/train/plugins/profile/2021_11_16_22_19_50\n",
      "\n",
      "2021-11-16 22:19:50.804963: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/train/plugins/profile/2021_11_16_22_19_50/LAPTOP-0TFTFNMR.memory_profile.json.gz\n",
      "2021-11-16 22:19:50.832808: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/train/plugins/profile/2021_11_16_22_19_50\n",
      "Dumped tool data for xplane.pb to logs/train/plugins/profile/2021_11_16_22_19_50/LAPTOP-0TFTFNMR.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/train/plugins/profile/2021_11_16_22_19_50/LAPTOP-0TFTFNMR.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/train/plugins/profile/2021_11_16_22_19_50/LAPTOP-0TFTFNMR.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/train/plugins/profile/2021_11_16_22_19_50/LAPTOP-0TFTFNMR.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/train/plugins/profile/2021_11_16_22_19_50/LAPTOP-0TFTFNMR.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671/671 [==============================] - 45s 63ms/step - loss: 0.5196 - mean_squared_error: 0.5196 - val_loss: 0.0479 - val_mean_squared_error: 0.0479\n",
      "Epoch 2/500\n",
      "640/671 [===========================>..] - ETA: 1s - loss: 0.5145 - mean_squared_error: 0.5145"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1285/1626198640.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mcallbackTb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcallbackTb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbackEs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbackHs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, dropout=0.05, return_sequences=True))\n",
    "model.add(LSTM(64, dropout=0.05))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "\n",
    "# Horovod: adjust learning rate based on the number of GPUs\n",
    "scaled_lr = 0.001 * hvd.size()\n",
    "opt = tf.optimizers.Adam(scaled_lr)\n",
    "# Horovod: adjust Horovod DistributedOptimizer\n",
    "opt = hvd.DistributedOptimizer(opt, backward_passes_per_step=1, average_aggregated_gradients=True)\n",
    "\n",
    "\n",
    "# Horovod: Specify `experimental_run_tf_function=False` to ensure TensorFlow \n",
    "# uses hvd.DistributedOptimizer() to compute gradients.\n",
    "# Adam optimiser allows high learning rate at first and speeds up training\n",
    "model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mean_squared_error'],experimental_run_tf_function=False)\n",
    "\n",
    "callbackHs = [\n",
    "    # Horovod: broadcast initial variable states from rank 0 to all other processes.\n",
    "    # This is necessary to ensure consistent initialization of all workers when\n",
    "    # training is started with random weights or restored from a checkpoint.\n",
    "    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\n",
    "    \n",
    "    # Horovod: average metrics among workers at the end of every epoch.\n",
    "    # Note: This callback must be in the list before the ReduceLROnPlateau,\n",
    "    # TensorBoard or other metrics-based callbacks.\n",
    "    hvd.callbacks.MetricAverageCallback(),\n",
    "    \n",
    "    # Horovod: using `lr = 1.0 * hvd.size()` from the very beginning leads to worse final\n",
    "    # accuracy. Scale the learning rate `lr = 1.0` ---> `lr = 1.0 * hvd.size()` during\n",
    "    # the first three epochs. See https://arxiv.org/abs/1706.02677 for details.\n",
    "    hvd.callbacks.LearningRateWarmupCallback(initial_lr=scaled_lr, warmup_epochs=3, verbose=1),\n",
    "]\n",
    "\n",
    "# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\n",
    "if hvd.rank() == 0:\n",
    "    callbackHs.append(tf.keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\n",
    "\n",
    "# Horovod: write logs on worker 0.\n",
    "verbose = 1 if hvd.rank() == 0 else 0\n",
    "\n",
    "# Early stop to prevent overfitting\n",
    "callbackEs = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Log performance using TensorBoard\n",
    "callbackTb = tf.keras.callbacks.TensorBoard()\n",
    "\n",
    "model.fit(x_train, y_train, shuffle=True, epochs=500, verbose=verbose, validation_data=(x_val, y_val), callbacks = [callbackTb, callbackEs,callbackHs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a1f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = model.predict(x_test)\n",
    "predicted = np.ravel(i)\n",
    "\n",
    "print(i)\n",
    "print(y_test)\n",
    "\n",
    "print(i.shape)\n",
    "print(y_val.shape)\n",
    "'''\n",
    "for x_test:\n",
    "    model.predict()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc91e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted2 = np.ravel(i)\n",
    "y_test2 = np.ravel(y_test)\n",
    "\n",
    "plt.title('Error')\n",
    "# Apply inverse transform to cancel the effects of MinMax scaler and Robust scaler to get back the original\n",
    "error = scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in predicted2]))[:,0] - scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in y_test2]))[:, 0]\n",
    "plt.plot(np.arange(len(error)), [0] * len(error))\n",
    "plt.plot(error)\n",
    "plt.fill_between(np.arange(len(error)), [0] * len(error), error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted3 = scaler2.inverse_transform([[x,0,0] for x in predicted2])[:,0].ravel()\n",
    "y_test3 = scaler2.inverse_transform([[x,0,0] for x in y_test2])[:,0].ravel()\n",
    "\n",
    "plt.title('Prediction (log scale)')\n",
    "plt.xlabel('Price USD (log)')\n",
    "plt.plot(predicted3,label=\"predict\")\n",
    "plt.plot(y_test3,label=\"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undo the log to see the actual price in USD\n",
    "predicted0 = np.exp(predicted3)-1\n",
    "y_test0 = np.exp(y_test3)-1\n",
    "\n",
    "plt.title('Prediction (actual)')\n",
    "plt.xlabel('Price USD')\n",
    "plt.plot(predicted0,label=\"predict\")\n",
    "plt.plot(y_test0,label=\"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    print('--------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d062193",
   "metadata": {},
   "outputs": [],
   "source": [
    "i3 = scaler2.inverse_transform([[x,0,0] for x in predicted2])[:,0].reshape(i.shape)\n",
    "y_test3 = scaler2.inverse_transform([[x,0,0] for x in y_test2])[:,0].reshape(y_test.shape)\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "for x in range(len(i3)):\n",
    "    plt.plot(np.arange(x,x+3), i3[x],'r--',label=\"predict\")\n",
    "for x1 in range(len(y_test)):\n",
    "    plt.plot(np.arange(x1,x1+3), y_test3[x1],'b-',label=\"real\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d600b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(80,120):\n",
    "    plt.plot(np.arange(x,x+3), i3[x],'r--',label=\"predict\")\n",
    "    plt.plot(np.arange(x,x+3), y_test3[x],'b-',label=\"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7534751",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2 = np.ravel(i)\n",
    "y_test2 = np.ravel(y_test)\n",
    "\n",
    "plt.title('Error')\n",
    "error = scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in predicted2]))[:,0] - scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in y_test2]))[:, 0]\n",
    "plt.plot(np.arange(len(error)), [0] * len(error))\n",
    "plt.plot(error)\n",
    "plt.fill_between(np.arange(len(error)), [0] * len(error), error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f04c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2 = np.ravel(i)\n",
    "y_test2 = np.ravel(y_test)\n",
    "\n",
    "plt.title('Error')\n",
    "error = scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in predicted2]))[:,0] - scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in y_test2]))[:, 0]\n",
    "plt.plot(np.arange(len(error)), [0] * len(error))\n",
    "plt.plot(error)\n",
    "plt.fill_between(np.arange(len(error)), [0] * len(error), error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfde855d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i3 = scaler2.inverse_transform([[x,0,0] for x in predicted2])[:,0].reshape(i.shape)\n",
    "y_test3 = scaler2.inverse_transform([[x,0,0] for x in y_test2])[:,0].reshape(y_test.shape)\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "for x in range(len(i3)):\n",
    "    plt.plot(np.arange(x,x+3), i3[x],'r--',label=\"predict\")\n",
    "for x1 in range(len(y_test)):\n",
    "    plt.plot(np.arange(x1,x1+3), y_test3[x1],'b-',label=\"real\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(120,170):\n",
    "    plt.plot(np.arange(x,x+3), i3[x],'r--',label=\"predict\")\n",
    "    plt.plot(np.arange(x,x+3), y_test3[x],'b-',label=\"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d59e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted2 = np.ravel(i)\n",
    "y_test2 = np.ravel(y_test)\n",
    "\n",
    "plt.title('Error')\n",
    "error = scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in predicted2]))[:,0] - scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in y_test2]))[:, 0]\n",
    "plt.plot(np.arange(len(error)), [0] * len(error))\n",
    "plt.plot(error)\n",
    "plt.fill_between(np.arange(len(error)), [0] * len(error), error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae435d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(200,210):\n",
    "    plt.plot(np.arange(x,x+3), i3[x],'r--',label=\"predict\")\n",
    "    plt.plot(np.arange(x,x+3), y_test3[x],'b-',label=\"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e2906",
   "metadata": {},
   "outputs": [],
   "source": [
    "i3 = scaler2.inverse_transform([[x,0,0] for x in predicted2])[:,0].reshape(i.shape)\n",
    "y_test3 = scaler2.inverse_transform([[x,0,0] for x in y_test2])[:,0].reshape(y_test.shape)\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "for x in range(len(i3)):\n",
    "    plt.plot(np.arange(x,x+3), i3[x],'r--',label=\"predict\")\n",
    "for x1 in range(len(y_test)):\n",
    "    plt.plot(np.arange(x1,x1+3), y_test3[x1],'b-',label=\"real\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a63bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in predicted]))[:,0], label='predict')\n",
    "plt.plot(scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in y_test]))[:, 0], label='actual')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Price BTC')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6630379",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in predicted]))[:,0], label='predict')\n",
    "plt.plot(scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in y_test]))[:, 0], label='actual')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Price USD')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fae295",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Error')\n",
    "error = scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in predicted]))[:,0] - scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in y_test]))[:, 0]\n",
    "plt.plot(np.arange(len(error)), [0] * len(error))\n",
    "plt.plot(error)\n",
    "plt.fill_between(np.arange(len(error)), [0] * len(error), error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d96261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in np.array(a[-946:])]))[:,0], label='predict')\n",
    "plt.plot(scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in predicted2]))[:50,0], label='predict')\n",
    "plt.plot(scaler.inverse_transform(scaler2.inverse_transform([[x,0,0] for x in y_test]))[:50, 0], label='actual')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Price USD')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a306ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
